#!/usr/bin/env python3
"""
Test Emotion Classifier - Phi-3-mini on vLLM
Benchmark latency v√† accuracy cho b√†i to√°n ph√¢n lo·∫°i emotion/celebrate
"""

import requests
import json
import time
import statistics
from typing import Dict, List, Tuple

# ============================================================
# CONFIGURATION
# ============================================================
API_URL = "http://localhost:7863/v1/chat/completions"  # Port c·ªßa Phi-3-mini server
MODEL_NAME = "microsoft/Phi-3-mini-4k-instruct"

# System prompt t·ªëi ∆∞u
SYSTEM_PROMPT = """You are a high-speed Mood & Celebrate Tagger for a child-robot interaction system.

# TASK
Analyze the robot's response and output JSON with 2 fields: emotion_name and celebrate.

# INSTRUCTIONS
1. Analyze user_last_message: Is user answering a factual question or just chatting?
2. Analyze pika_response for emotion
3. celebrate Logic:
   - "yes" ONLY IF Pika confirms user answered a FACTUAL question correctly
   - "no" for ALL other cases (opinions, ideas, general chat)

# EMOTION TAGS
happy, calm, excited, playful, encouraging, curious, surprised, proud, sad, thats_right, worry, thinking, celebration

# OUTPUT FORMAT (JSON only, no explanation)
{"emotion_name": "<tag>", "celebrate": "yes"|"no"}

# EXAMPLES

Example 1: Factual Q&A ‚Üí celebrate: yes
user_last_message: "Con voi ƒÉn c·ªè ·∫°"
pika_response: "ƒê√∫ng r·ªìi, con gi·ªèi l·∫Øm!"
Output: {"emotion_name": "proud", "celebrate": "yes"}

Example 2: Opinion ‚Üí celebrate: no
user_last_message: "T·ªõ th√≠ch m√†u xanh"
pika_response: "·ªí, m√†u xanh ƒë·∫πp th·∫≠t!"
Output: {"emotion_name": "happy", "celebrate": "no"}

Example 3: Wrong answer ‚Üí celebrate: no
user_last_message: "2+2=5"
pika_response: "Ch∆∞a ƒë√∫ng r·ªìi, th·ª≠ l·∫°i nh√©!"
Output: {"emotion_name": "encouraging", "celebrate": "no"}

NOW ANALYZE:"""


# ============================================================
# TEST CASES
# ============================================================
TEST_CASES = [
    # Celebrate = YES cases
    {
        "name": "Factual Q&A - Geography",
        "user": "Th·ªß ƒë√¥ c·ªßa Vi·ªát Nam l√† H√† N·ªôi ·∫°!",
        "pika": "Ch√≠nh x√°c! Con th√¥ng minh l·∫Øm! H√† N·ªôi l√† th·ªß ƒë√¥ c·ªßa n∆∞·ªõc ta ƒë√≥.",
        "expected_celebrate": "yes",
        "expected_emotions": ["proud", "excited", "happy"]
    },
    {
        "name": "Factual Q&A - Math",
        "user": "2 c·ªông 3 b·∫±ng 5 ·∫°!",
        "pika": "ƒê√∫ng r·ªìi! Con t√≠nh gi·ªèi qu√°! 2+3 ƒë√∫ng l√† b·∫±ng 5.",
        "expected_celebrate": "yes",
        "expected_emotions": ["proud", "excited", "happy", "thats_right"]
    },
    {
        "name": "Factual Q&A - English",
        "user": "Apple nghƒ©a l√† qu·∫£ t√°o!",
        "pika": "Excellent! ƒê√∫ng r·ªìi, apple l√† qu·∫£ t√°o. Con gi·ªèi ti·∫øng Anh qu√°!",
        "expected_celebrate": "yes",
        "expected_emotions": ["proud", "excited", "celebration"]
    },
    
    # Celebrate = NO cases
    {
        "name": "Opinion - Favorite color",
        "user": "T·ªõ th√≠ch m√†u h·ªìng nh·∫•t!",
        "pika": "·ªí, m√†u h·ªìng xinh x·∫Øn th·∫≠t! T·ªõ c≈©ng th√≠ch m√†u h·ªìng ƒë·∫•y.",
        "expected_celebrate": "no",
        "expected_emotions": ["happy", "excited", "surprised"]
    },
    {
        "name": "Opinion - Favorite food",
        "user": "Con th√≠ch ƒÉn kem chocolate!",
        "pika": "Wow, kem chocolate ngon tuy·ªát! ƒê√≥ c≈©ng l√† v·ªã kem y√™u th√≠ch c·ªßa t·ªõ ƒë√≥.",
        "expected_celebrate": "no",
        "expected_emotions": ["happy", "excited", "surprised"]
    },
    {
        "name": "Wrong answer",
        "user": "5 nh√¢n 3 b·∫±ng 12 ·∫°",
        "pika": "∆†, ch∆∞a ƒë√∫ng l·∫Øm r·ªìi! Th·ª≠ ƒë·∫øm l·∫°i xem, 5 l·∫ßn 3 l√† m·∫•y nh·ªâ?",
        "expected_celebrate": "no",
        "expected_emotions": ["encouraging", "curious", "calm"]
    },
    {
        "name": "General chat - Feeling",
        "user": "H√¥m nay t·ªõ r·∫•t vui!",
        "pika": "Tuy·ªát v·ªùi! T·ªõ c≈©ng r·∫•t vui khi ƒë∆∞·ª£c tr√≤ chuy·ªán c√πng c·∫≠u!",
        "expected_celebrate": "no",
        "expected_emotions": ["happy", "excited"]
    },
    {
        "name": "General chat - Activity",
        "user": "T·ªõ v·ª´a ƒëi ch∆°i c√¥ng vi√™n v·ªÅ!",
        "pika": "Nghe vui qu√°! C·∫≠u ch∆°i g√¨ ·ªü c√¥ng vi√™n v·∫≠y?",
        "expected_celebrate": "no",
        "expected_emotions": ["curious", "happy", "excited"]
    },
    {
        "name": "Idea suggestion",
        "user": "Hay l√† m√¨nh ch∆°i tr√≤ ƒë·ªë vui ƒëi!",
        "pika": "√ù t∆∞·ªüng hay qu√°! T·ªõ r·∫•t th√≠ch ch∆°i ƒë·ªë vui ƒë√≥!",
        "expected_celebrate": "no",
        "expected_emotions": ["excited", "happy", "playful"]
    },
]


def classify_emotion(user_msg: str, pika_response: str) -> Tuple[Dict, float]:
    """
    G·ªçi API ƒë·ªÉ ph√¢n lo·∫°i emotion
    Returns: (result_dict, latency_ms)
    """
    user_content = f"""user_last_message: "{user_msg}"
pika_response: "{pika_response}"
Output:"""
    
    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_content}
        ],
        "temperature": 0,
        "max_tokens": 50,
    }
    
    start_time = time.time()
    try:
        response = requests.post(API_URL, json=payload, timeout=10)
        latency = (time.time() - start_time) * 1000
        
        if response.status_code == 200:
            result = response.json()
            content = result['choices'][0]['message']['content'].strip()
            
            # Parse JSON t·ª´ response
            # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p c√≥ markdown code block
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()
            
            parsed = json.loads(content)
            return parsed, latency
        else:
            return {"error": f"HTTP {response.status_code}"}, latency
            
    except json.JSONDecodeError as e:
        return {"error": f"JSON parse error: {content[:100]}"}, latency
    except Exception as e:
        return {"error": str(e)}, 0


def run_benchmark(num_warmup: int = 3, num_runs: int = 10):
    """
    Ch·∫°y benchmark v·ªõi warmup v√† multiple runs
    """
    print("\n" + "="*70)
    print("üß™ EMOTION CLASSIFIER BENCHMARK - Phi-3-mini on vLLM")
    print("="*70)
    
    # Warmup
    print(f"\nüî• Warming up ({num_warmup} requests)...")
    for i in range(num_warmup):
        classify_emotion("Test", "Test response")
    print("   Warmup complete.")
    
    # Run tests
    all_latencies = []
    results = []
    
    print(f"\nüìä Running {len(TEST_CASES)} test cases ({num_runs}x each)...\n")
    print("-"*70)
    
    for test in TEST_CASES:
        test_latencies = []
        last_result = None
        
        for _ in range(num_runs):
            result, latency = classify_emotion(test['user'], test['pika'])
            test_latencies.append(latency)
            last_result = result
        
        avg_latency = statistics.mean(test_latencies)
        all_latencies.extend(test_latencies)
        
        # Check accuracy
        celebrate_correct = False
        emotion_correct = False
        
        if 'error' not in last_result:
            celebrate_correct = last_result.get('celebrate', '').lower() == test['expected_celebrate']
            emotion_correct = last_result.get('emotion_name', '') in test['expected_emotions']
        
        status = "‚úÖ" if (celebrate_correct and emotion_correct) else "‚ùå"
        celebrate_status = "‚úì" if celebrate_correct else "‚úó"
        emotion_status = "‚úì" if emotion_correct else "‚úó"
        
        print(f"{status} {test['name'][:35]:35s} | {avg_latency:6.1f}ms | "
              f"celebrate:{celebrate_status} emotion:{emotion_status}")
        
        if 'error' not in last_result:
            print(f"   ‚Üí Got: emotion={last_result.get('emotion_name')}, "
                  f"celebrate={last_result.get('celebrate')}")
        else:
            print(f"   ‚Üí Error: {last_result['error']}")
        
        results.append({
            "name": test['name'],
            "latency_avg": avg_latency,
            "celebrate_correct": celebrate_correct,
            "emotion_correct": emotion_correct,
            "result": last_result
        })
    
    # Summary statistics
    print("\n" + "="*70)
    print("üìà SUMMARY STATISTICS")
    print("="*70)
    
    total_tests = len(results)
    celebrate_accuracy = sum(1 for r in results if r['celebrate_correct']) / total_tests * 100
    emotion_accuracy = sum(1 for r in results if r['emotion_correct']) / total_tests * 100
    
    print(f"\nüéØ Accuracy:")
    print(f"   ‚Ä¢ Celebrate detection: {celebrate_accuracy:.1f}% ({sum(1 for r in results if r['celebrate_correct'])}/{total_tests})")
    print(f"   ‚Ä¢ Emotion detection:   {emotion_accuracy:.1f}% ({sum(1 for r in results if r['emotion_correct'])}/{total_tests})")
    
    print(f"\n‚è±Ô∏è  Latency (total {len(all_latencies)} requests):")
    print(f"   ‚Ä¢ Min:    {min(all_latencies):.1f}ms")
    print(f"   ‚Ä¢ Max:    {max(all_latencies):.1f}ms")
    print(f"   ‚Ä¢ Mean:   {statistics.mean(all_latencies):.1f}ms")
    print(f"   ‚Ä¢ Median: {statistics.median(all_latencies):.1f}ms")
    print(f"   ‚Ä¢ Stdev:  {statistics.stdev(all_latencies):.1f}ms")
    print(f"   ‚Ä¢ P95:    {sorted(all_latencies)[int(len(all_latencies)*0.95)]:.1f}ms")
    print(f"   ‚Ä¢ P99:    {sorted(all_latencies)[int(len(all_latencies)*0.99)]:.1f}ms")
    
    # Target check
    print(f"\nüéØ Target Check:")
    target_50ms = sum(1 for l in all_latencies if l < 50) / len(all_latencies) * 100
    target_75ms = sum(1 for l in all_latencies if l < 75) / len(all_latencies) * 100
    print(f"   ‚Ä¢ < 50ms: {target_50ms:.1f}% requests")
    print(f"   ‚Ä¢ < 75ms: {target_75ms:.1f}% requests")
    
    if statistics.mean(all_latencies) < 50 and celebrate_accuracy >= 90:
        print(f"\n‚úÖ SUCCESS! System meets requirements:")
        print(f"   ‚Ä¢ Latency < 50ms ‚úì")
        print(f"   ‚Ä¢ Celebrate accuracy >= 90% ‚úì")
    else:
        print(f"\n‚ö†Ô∏è  System needs optimization:")
        if statistics.mean(all_latencies) >= 50:
            print(f"   ‚Ä¢ Latency: {statistics.mean(all_latencies):.1f}ms > 50ms target")
        if celebrate_accuracy < 90:
            print(f"   ‚Ä¢ Celebrate accuracy: {celebrate_accuracy:.1f}% < 90% target")
    
    print("\n" + "="*70)
    return results


def quick_test():
    """Quick single test ƒë·ªÉ verify server ho·∫°t ƒë·ªông"""
    print("\nüîç Quick connectivity test...")
    
    try:
        result, latency = classify_emotion(
            "Th·ªß ƒë√¥ c·ªßa Vi·ªát Nam l√† H√† N·ªôi",
            "ƒê√∫ng r·ªìi! Con gi·ªèi l·∫Øm!"
        )
        
        if 'error' in result:
            print(f"‚ùå Error: {result['error']}")
            return False
        
        print(f"‚úÖ Server responding!")
        print(f"   ‚Ä¢ Latency: {latency:.1f}ms")
        print(f"   ‚Ä¢ Result: {result}")
        return True
        
    except requests.exceptions.ConnectionError:
        print(f"‚ùå Cannot connect to {API_URL}")
        print(f"   Make sure vLLM server is running on port 7863")
        return False


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--quick":
        quick_test()
    else:
        if quick_test():
            print("\n" + "="*70)
            run_benchmark(num_warmup=3, num_runs=5)